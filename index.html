<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="WideDepth: Millimeter-Accurate Benchmark for Fisheye Depth Estimation - Ilia Indyk, John Doe">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="WideDepth introduces the first millimeter-accurate indoor fisheye depth benchmark with 5K stereo pairs, adaptation methods for pinhole models and a large LiDAR-based training set.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="fisheye depth estimation, robotics, stereo vision, dataset, benchmark">
  <!-- TODO: List all authors -->
  <meta name="author" content="Ilia Indyk, John Doe">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Robotics Center &amp; AIRI">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="WideDepth: Millimeter-Accurate Benchmark for Fisheye Depth Estimation">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="WideDepth introduces the first millimeter-accurate indoor fisheye depth benchmark with 5K stereo pairs, adaptation methods for pinhole models and a large LiDAR-based training set.">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="static/index.html">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="WideDepth - Research Preview">
  <meta property="article:published_time" content="2026-02-04T00:00:00.000Z">
  <meta property="article:author" content="Ilia Indyk">
  <meta property="article:section" content="Robotics">
  <meta property="article:tag" content="fisheye depth estimation">
  <meta property="article:tag" content="stereo vision">

  <!-- Twitter -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <!-- <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE"> -->
  <!-- TODO: Replace with first author's Twitter handle -->
  <!-- <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE"> -->
  <!-- TODO: Same as paper title above -->
  <!-- <meta name="twitter:title" content="PAPER_TITLE"> -->
  <!-- TODO: Same as description above -->
  <!-- <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS"> -->
  <!-- TODO: Same as social preview image above -->
  <!-- <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="PAPER_TITLE - Research Preview"> -->

  <!-- Academic/Research Specific -->
  <!-- <meta name="citation_title" content="PAPER_TITLE">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf"> -->
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>WideDepth: Millimeter-Accurate Benchmark for Fisheye Depth Estimation</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/widedepth_favicon.ico">
  <link rel="apple-touch-icon" href="static/images/widedepth_favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <!-- <script type="application/ld+json"> -->
  <!-- {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  } -->
  <!-- </script> -->
  
  <!-- Website/Organization Structured Data -->
  <!-- <script type="application/ld+json"> -->
  <!-- {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script> -->
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">WideDepth: Millimeter-Accurate Benchmark for Fisheye Depth Estimation</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                Ilia Indyk<sup>1</sup>,</span>
                <span class="author-block">
                Ignat Penshin<sup>1</sup>,</span>
                <span class="author-block">
                Ivan Sosin<sup>1</sup>,</span>
                <span class="author-block">
                Maxim Monastyrny<sup>1</sup>,</span>
                <span class="author-block">
                Aleksei Valenkov<sup>1</sup>,</span>
                <span class="author-block">
                Ilya Makarov<sup>2</sup></span>
                </span>
                </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <span class="affil affil-1"><sup>1</sup>Robotics Center</span>,
                      <span class="affil affil-2"><sup>2</sup>AXXX</span>
                      <br> <b>ICRA 2026</b>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="static/pdfs/WideDepth_ICRA_2026.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="#" target="_blank"
                    class="external-link button is-normal is-rounded is-dark disabled-link"
                    aria-disabled="true"
                    title="Coming soon">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (coming soon)</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (coming soon)</span> -->

                <span class="link-block">
                  <a href="#"
                    class="external-link button is-normal is-rounded is-dark disabled-link"
                    aria-disabled="true"
                    title="Coming soon">
                    <span class="icon"><i class="fas fa-database"></i></span>
                    <span>Dataset (coming soon)</span>
                  </a>
                </span>

                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <figure class="image">
        <img src="static/images/banner.jpg"
             alt="WideDepth pipeline overview"
             loading="lazy"
             style="width:100%; height:auto; border-radius:12px;">
      </figure>

      <h2 class="subtitle has-text-centered" style="margin-top: 0.75rem;">
        Overview of our proposed pipeline for generating fisheye stereo RGB, depth, and disparity from LiDAR scans.
      </h2>

    </div>
  </div>
</section>
<!-- End teaser image -->


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Fisheye cameras are increasingly adopted in robotics for near-field manipulation, navigation, and immersive perception, yet indoor depth benchmarks with accurate ground truth are still missing.
            To address this, we introduce WideDepth — the first indoor dataset for fisheye depth estimation, featuring 101 scenes containing 5K high-resolution stereo pairs labeled with millimeter-level ground truth depth and disparity.
            Our dataset also includes paired pinhole and fisheye samples across varying fields of view and baselines in both horizontal and vertical stereo setups. 
            We further propose a method to adapt pinhole-trained stereo models to fisheye images and introduce a novel stereo fisheye image generation pipeline based on high-resolution LiDAR scans. 
            Leveraging these methods, we thoroughly evaluate state-of-the-art monocular depth, stereo matching, and depth completion models on our benchmark. 
            Additionally, we provide 18K LiDAR-derived sparse depth training samples, achieving up to a 62% performance boost on fisheye data when fine-tuning pinhole-based stereo models. 
            In summary, the high precision and versatility of our benchmark set a strong foundation for advancing research in fisheye depth estimation and robotics perception.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/ICRA26_3467_video.mp4" type="video/mp4">
      </video>
    </div>
  </div>
</section> -->
<!-- End teaser video -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       
        <div class="item">
        <img src="static/images/table_1.png" alt="Comparison table with other fisheye datasets" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Our benchmark offers unparalleled precision of depth maps, leveraging varying FOV and high-resolution images, surpassing all existing fisheye datasets. 
          Our training dataset is the first-ever with a vertical stereo setup. 
        </h2>
      </div>
      
      <div class="item">
        <img src="static/images/stereo_qual_screenshot.png" alt="Stereo qualitative results" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Qualitative results for stereo with FOV 195 using the StereoBase model. 
          The model shows no degradation from geometric distortion, demonstrating the success of our approach in adapting pinhole models to fisheye data.
        </h2>
      </div>
      
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/mono_qualitative.png" alt="Mono qualitative results" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Comparison of the best and worst models on a 195-degree FOV.
         Despite its ability to distinguish small details well, Depth Anything V2 performs significantly worse in metric depth estimation on extremely wide angles compared to Depth Pro.
       </h2>
     </div>
     
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- YouTube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe width="560" height="315" 
            src="https://www.youtube.com/embed/zmxO8p5tIB8?si=ewaBo_oQMgzhSZze" 
            title="Video presentation" 
            frameborder="0" 
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
            referrerpolicy="strict-origin-when-cross-origin" 
            allowfullscreen>
            </iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End YouTube video -->


<!-- Video Presentation (local file) -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">

            <video
              controls
              preload="metadata"
              playsinline
              style="width: 100%; height: auto; border-radius: 12px;">
              <source src="static/videos/ICRA26_3467_video.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>

          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video presentation -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->



<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Your Paper Title Here},
  author={First Author and Second Author and Third Author},
  journal={Conference/Journal Name},
  year={2024},
  url={https://your-domain.com/your-project-page}
}</code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <!-- <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>. -->
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
